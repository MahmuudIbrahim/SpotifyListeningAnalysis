{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23cf9f4",
   "metadata": {},
   "source": [
    "# Day 1 — Build Dataset + EDA (Spotify Streaming History → Modeling Tables)\n",
    "\n",
    "**Goal:** Create clean, enriched datasets from your personal Spotify streaming history (2012–2023) and generate a small set of story-ready EDA visuals.\n",
    "\n",
    "**Outputs written by this notebook**\n",
    "- `data/processed/listens_event_level.parquet` (one row per play)\n",
    "- `data/processed/tracks_modeling_table.parquet` (one row per track; ready for Day 2)\n",
    "- `data/processed/artists_modeling_table.parquet` (one row per artist; optional)\n",
    "- `data/cache/audio_features.parquet` (Spotify track audio features + metadata cache)\n",
    "- `data/cache/artist_genres.json` (Spotify artist genres cache)\n",
    "\n",
    "**Expected runtime:** depends on how many unique tracks/artists you have and your Spotify API rate limits. Caching prevents repeated calls.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup checklist\n",
    "1. Create a Spotify Developer app and set `SPOTIPY_CLIENT_ID`, `SPOTIPY_CLIENT_SECRET`, `SPOTIPY_REDIRECT_URI` as environment variables.\n",
    "2. Install deps: `pip install spotipy pandas numpy matplotlib plotly tqdm python-dotenv pyarrow`\n",
    "3. (Optional) Add a CJK-capable font (Noto Sans CJK) to avoid tofu boxes in plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193aa0f8-bb80-4134-a488-7848cfc75c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"spotipy\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f264fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Dict, Any, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: load .env in local dev\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89225ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\maxma\\Documents\\Spotify Project\n",
      "Loaded config.py\n"
     ]
    }
   ],
   "source": [
    "# Repo root + config setup (for notebooks/ execution)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "HERE = Path().resolve()\n",
    "ROOT_DIR = HERE\n",
    "# Walk upward until we find config.py (repo root marker)\n",
    "while not (ROOT_DIR / 'config.py').exists() and ROOT_DIR != ROOT_DIR.parent:\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "\n",
    "if not (ROOT_DIR / 'config.py').exists():\n",
    "    raise RuntimeError(\n",
    "        \"config.py not found. Create it at the repo root (or copy config_template.py -> config.py).\"\n",
    "    )\n",
    "\n",
    "# Ensure repo root is importable\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "import config\n",
    "print('Repo root:', ROOT_DIR)\n",
    "print('Loaded config.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c60ad5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_DIR: C:\\Users\\maxma\\Documents\\Spotify Project\n",
      "RAW_DIR: C:\\Users\\maxma\\Documents\\Spotify Project\\data\\raw\n",
      "DEFAULT_INPUT_DIR: C:\\Users\\maxma\\Documents\\Spotify Project\\data\\raw\\spotify\n"
     ]
    }
   ],
   "source": [
    "# Paths (rooted at repo root so running from notebooks/ works)\n",
    "PROJECT_DIR = ROOT_DIR\n",
    "DATA_DIR = PROJECT_DIR / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "CACHE_DIR = DATA_DIR / 'cache'\n",
    "FIG_DIR = PROJECT_DIR / 'reports' / 'figures'\n",
    "\n",
    "for d in [RAW_DIR, PROCESSED_DIR, CACHE_DIR, FIG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('PROJECT_DIR:', PROJECT_DIR)\n",
    "print('RAW_DIR:', RAW_DIR)\n",
    "\n",
    "# Default location for Spotify JSONs\n",
    "DEFAULT_INPUT_DIR = RAW_DIR / 'spotify'\n",
    "# Fallback for sandbox runs (this repo uses /mnt/data)\n",
    "if not DEFAULT_INPUT_DIR.exists():\n",
    "    sandbox_dir = Path('/mnt/data')\n",
    "    if sandbox_dir.exists():\n",
    "        DEFAULT_INPUT_DIR = sandbox_dir\n",
    "\n",
    "print('DEFAULT_INPUT_DIR:', DEFAULT_INPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7992c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CJK font chosen: (fallback DejaVu Sans; install Noto Sans CJK for better coverage)\n"
     ]
    }
   ],
   "source": [
    "# CJK-safe plotting helper\n",
    "\n",
    "def set_cjk_font(preferred_fonts: Optional[list[str]] = None) -> Optional[str]:\n",
    "    # Attempt to set a CJK-capable font. Returns chosen font name (or None).\n",
    "    if preferred_fonts is None:\n",
    "        preferred_fonts = [\n",
    "            'Noto Sans CJK JP',\n",
    "            'Noto Sans CJK KR',\n",
    "            'Noto Sans CJK SC',\n",
    "            'Noto Sans JP',\n",
    "            'Arial Unicode MS',\n",
    "        ]\n",
    "\n",
    "    available = {f.name for f in mpl.font_manager.fontManager.ttflist}\n",
    "    for name in preferred_fonts:\n",
    "        if name in available:\n",
    "            mpl.rcParams['font.family'] = name\n",
    "            mpl.rcParams['axes.unicode_minus'] = False\n",
    "            return name\n",
    "\n",
    "    # Fallback: DejaVu is commonly available but may not cover CJK fully\n",
    "    mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
    "    mpl.rcParams['axes.unicode_minus'] = False\n",
    "    return None\n",
    "\n",
    "chosen = set_cjk_font()\n",
    "print('CJK font chosen:' , chosen or '(fallback DejaVu Sans; install Noto Sans CJK for better coverage)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba7437",
   "metadata": {},
   "source": [
    "## 1) Load + clean streaming history JSONs\n",
    "\n",
    "We will:\n",
    "- Read all `Streaming_History_Audio_*.json` files\n",
    "- Keep only music tracks (exclude podcast episodes)\n",
    "- Parse timestamps, build time features\n",
    "- Keep raw playback facts: `ms_played`, `skipped`, start/end reasons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd4d1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567afdcf27da4fea8b185297f132a364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading streaming history JSON:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>username</th>\n",
       "      <th>platform</th>\n",
       "      <th>ms_played</th>\n",
       "      <th>conn_country</th>\n",
       "      <th>ip_addr_decrypted</th>\n",
       "      <th>user_agent_decrypted</th>\n",
       "      <th>master_metadata_track_name</th>\n",
       "      <th>master_metadata_album_artist_name</th>\n",
       "      <th>master_metadata_album_album_name</th>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_show_name</th>\n",
       "      <th>spotify_episode_uri</th>\n",
       "      <th>reason_start</th>\n",
       "      <th>reason_end</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>skipped</th>\n",
       "      <th>offline</th>\n",
       "      <th>offline_timestamp</th>\n",
       "      <th>incognito_mode</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-08-31T17:21:11Z</td>\n",
       "      <td>1246157207</td>\n",
       "      <td>iOS 5.1.1 (iPhone3,3)</td>\n",
       "      <td>21966</td>\n",
       "      <td>US</td>\n",
       "      <td>174.229.2.243</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Kill Shit</td>\n",
       "      <td>Krizz Kaliko</td>\n",
       "      <td>Kickin' &amp; Screamin'</td>\n",
       "      <td>spotify:track:3eMfBkKz0ZuffMqIVHhNr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Streaming_History_Audio_2012-2014_0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-31T17:30:20Z</td>\n",
       "      <td>1246157207</td>\n",
       "      <td>iOS 5.1.1 (iPhone3,3)</td>\n",
       "      <td>454489</td>\n",
       "      <td>US</td>\n",
       "      <td>174.229.2.243</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Mayday</td>\n",
       "      <td>Krizz Kaliko</td>\n",
       "      <td>Kickin' &amp; Screamin'</td>\n",
       "      <td>spotify:track:44eZ0RG3gWBfiD5o9pvIV9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>trackdone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Streaming_History_Audio_2012-2014_0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-08-31T17:31:17Z</td>\n",
       "      <td>1246157207</td>\n",
       "      <td>iOS 5.1.1 (iPhone3,3)</td>\n",
       "      <td>59112</td>\n",
       "      <td>US</td>\n",
       "      <td>174.229.2.243</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Dumb For You</td>\n",
       "      <td>Krizz Kaliko</td>\n",
       "      <td>Kickin' &amp; Screamin'</td>\n",
       "      <td>spotify:track:0uQWGMWQAtpISoXTEi5as6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trackdone</td>\n",
       "      <td>backbtn</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Streaming_History_Audio_2012-2014_0.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ts    username               platform  ms_played conn_country ip_addr_decrypted user_agent_decrypted master_metadata_track_name  \\\n",
       "0  2012-08-31T17:21:11Z  1246157207  iOS 5.1.1 (iPhone3,3)      21966           US     174.229.2.243              unknown                  Kill Shit   \n",
       "1  2012-08-31T17:30:20Z  1246157207  iOS 5.1.1 (iPhone3,3)     454489           US     174.229.2.243              unknown                     Mayday   \n",
       "2  2012-08-31T17:31:17Z  1246157207  iOS 5.1.1 (iPhone3,3)      59112           US     174.229.2.243              unknown               Dumb For You   \n",
       "\n",
       "  master_metadata_album_artist_name master_metadata_album_album_name                     spotify_track_uri episode_name episode_show_name spotify_episode_uri  \\\n",
       "0                      Krizz Kaliko              Kickin' & Screamin'  spotify:track:3eMfBkKz0ZuffMqIVHhNr1          NaN               NaN                 NaN   \n",
       "1                      Krizz Kaliko              Kickin' & Screamin'  spotify:track:44eZ0RG3gWBfiD5o9pvIV9          NaN               NaN                 NaN   \n",
       "2                      Krizz Kaliko              Kickin' & Screamin'  spotify:track:0uQWGMWQAtpISoXTEi5as6          NaN               NaN                 NaN   \n",
       "\n",
       "  reason_start reason_end  shuffle skipped  offline  offline_timestamp  incognito_mode                               source_file  \n",
       "0                            False    True    False                  0           False  Streaming_History_Audio_2012-2014_0.json  \n",
       "1               trackdone    False   False    False                  0           False  Streaming_History_Audio_2012-2014_0.json  \n",
       "2    trackdone    backbtn    False    True    False                  0           False  Streaming_History_Audio_2012-2014_0.json  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_streaming_history(input_dir: Path) -> pd.DataFrame:\n",
    "    files = sorted(input_dir.glob('Streaming_History_Audio_*.json'))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f'No Streaming_History_Audio_*.json found in {input_dir}')\n",
    "\n",
    "    dfs = []\n",
    "    for fp in tqdm(files, desc='Reading streaming history JSON'):\n",
    "        df = pd.read_json(fp)\n",
    "        df['source_file'] = fp.name\n",
    "        dfs.append(df)\n",
    "\n",
    "    out = pd.concat(dfs, ignore_index=True)\n",
    "    return out\n",
    "\n",
    "raw_df = load_streaming_history(DEFAULT_INPUT_DIR)\n",
    "raw_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b233f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxma\\AppData\\Local\\Temp\\ipykernel_36800\\3514461304.py:27: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df['year_month'] = df['ts'].dt.to_period('M').astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 136946\n",
      "unique tracks: 25516\n",
      "unique artists: 6144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>year_month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>album_name</th>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <th>ms_played</th>\n",
       "      <th>seconds_played</th>\n",
       "      <th>skipped</th>\n",
       "      <th>reason_start</th>\n",
       "      <th>reason_end</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>platform</th>\n",
       "      <th>conn_country</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-08-31 17:21:11+00:00</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Kill Shit</td>\n",
       "      <td>Krizz Kaliko</td>\n",
       "      <td>Kickin' &amp; Screamin'</td>\n",
       "      <td>spotify:track:3eMfBkKz0ZuffMqIVHhNr1</td>\n",
       "      <td>21966</td>\n",
       "      <td>21.966</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>iOS 5.1.1 (iPhone3,3)</td>\n",
       "      <td>US</td>\n",
       "      <td>Streaming_History_Audio_2012-2014_0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-31 17:30:20+00:00</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Mayday</td>\n",
       "      <td>Krizz Kaliko</td>\n",
       "      <td>Kickin' &amp; Screamin'</td>\n",
       "      <td>spotify:track:44eZ0RG3gWBfiD5o9pvIV9</td>\n",
       "      <td>454489</td>\n",
       "      <td>454.489</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>trackdone</td>\n",
       "      <td>False</td>\n",
       "      <td>iOS 5.1.1 (iPhone3,3)</td>\n",
       "      <td>US</td>\n",
       "      <td>Streaming_History_Audio_2012-2014_0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-08-31 17:31:17+00:00</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2012-08</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Dumb For You</td>\n",
       "      <td>Krizz Kaliko</td>\n",
       "      <td>Kickin' &amp; Screamin'</td>\n",
       "      <td>spotify:track:0uQWGMWQAtpISoXTEi5as6</td>\n",
       "      <td>59112</td>\n",
       "      <td>59.112</td>\n",
       "      <td>True</td>\n",
       "      <td>trackdone</td>\n",
       "      <td>backbtn</td>\n",
       "      <td>False</td>\n",
       "      <td>iOS 5.1.1 (iPhone3,3)</td>\n",
       "      <td>US</td>\n",
       "      <td>Streaming_History_Audio_2012-2014_0.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ts        date  year  month year_month  dayofweek  hour    track_name   artist_name           album_name  \\\n",
       "0 2012-08-31 17:21:11+00:00  2012-08-31  2012      8    2012-08          4    17     Kill Shit  Krizz Kaliko  Kickin' & Screamin'   \n",
       "1 2012-08-31 17:30:20+00:00  2012-08-31  2012      8    2012-08          4    17        Mayday  Krizz Kaliko  Kickin' & Screamin'   \n",
       "2 2012-08-31 17:31:17+00:00  2012-08-31  2012      8    2012-08          4    17  Dumb For You  Krizz Kaliko  Kickin' & Screamin'   \n",
       "\n",
       "                      spotify_track_uri  ms_played  seconds_played  skipped reason_start reason_end  shuffle               platform conn_country  \\\n",
       "0  spotify:track:3eMfBkKz0ZuffMqIVHhNr1      21966          21.966     True                            False  iOS 5.1.1 (iPhone3,3)           US   \n",
       "1  spotify:track:44eZ0RG3gWBfiD5o9pvIV9     454489         454.489    False               trackdone    False  iOS 5.1.1 (iPhone3,3)           US   \n",
       "2  spotify:track:0uQWGMWQAtpISoXTEi5as6      59112          59.112     True    trackdone    backbtn    False  iOS 5.1.1 (iPhone3,3)           US   \n",
       "\n",
       "                                source_file  \n",
       "0  Streaming_History_Audio_2012-2014_0.json  \n",
       "1  Streaming_History_Audio_2012-2014_0.json  \n",
       "2  Streaming_History_Audio_2012-2014_0.json  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_streaming_history(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Keep only music tracks (exclude podcast episodes)\n",
    "    df = df.copy()\n",
    "\n",
    "    # Standardize timestamp\n",
    "    df['ts'] = pd.to_datetime(df['ts'], utc=True, errors='coerce')\n",
    "\n",
    "    # Spotify exports sometimes include episodes; keep rows with track URIs\n",
    "    df = df[df['spotify_track_uri'].notna()].copy()\n",
    "\n",
    "    # Keep key identifiers\n",
    "    df.rename(columns={\n",
    "        'master_metadata_track_name': 'track_name',\n",
    "        'master_metadata_album_artist_name': 'artist_name',\n",
    "        'master_metadata_album_album_name': 'album_name',\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Basic sanity\n",
    "    df['ms_played'] = pd.to_numeric(df['ms_played'], errors='coerce')\n",
    "    df = df[df['ms_played'].notna()].copy()\n",
    "    df = df[df['ms_played'] > 0].copy()\n",
    "\n",
    "    # Time features\n",
    "    df['date'] = df['ts'].dt.date\n",
    "    df['year'] = df['ts'].dt.year\n",
    "    df['month'] = df['ts'].dt.month\n",
    "    df['year_month'] = df['ts'].dt.to_period('M').astype(str)\n",
    "    df['dayofweek'] = df['ts'].dt.dayofweek\n",
    "    df['hour'] = df['ts'].dt.hour\n",
    "\n",
    "    # Playback features\n",
    "    df['seconds_played'] = df['ms_played'] / 1000.0\n",
    "\n",
    "    # Ensure boolean-ish skipped field\n",
    "    if 'skipped' in df.columns:\n",
    "        df['skipped'] = df['skipped'].fillna(False).astype(bool)\n",
    "    else:\n",
    "        df['skipped'] = False\n",
    "\n",
    "    # Minimal columns for event-level modeling\n",
    "    keep = [\n",
    "        'ts','date','year','month','year_month','dayofweek','hour',\n",
    "        'track_name','artist_name','album_name','spotify_track_uri',\n",
    "        'ms_played','seconds_played','skipped',\n",
    "        'reason_start','reason_end','shuffle','platform','conn_country','source_file'\n",
    "    ]\n",
    "    keep = [c for c in keep if c in df.columns]\n",
    "    df = df[keep].copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = clean_streaming_history(raw_df)\n",
    "print('rows:', len(df))\n",
    "print('unique tracks:', df['spotify_track_uri'].nunique())\n",
    "print('unique artists:', df['artist_name'].nunique())\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bed76f",
   "metadata": {},
   "source": [
    "## 2) Spotify API enrichment (cached)\n",
    "\n",
    "We will add:\n",
    "- Track metadata: `track_id`, `track_popularity`, `duration_ms`, `explicit`, `album_release_date`\n",
    "- Audio features: danceability, energy, valence, tempo, etc.\n",
    "\n",
    "We cache results to `data/cache/audio_features.parquet`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f997cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spotify API OK. Sample track: Test & Recognise (Flume Re-work)\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "sp = spotipy.Spotify(\n",
    "    auth_manager=SpotifyClientCredentials(\n",
    "        client_id=config.spotify[\"client_id\"],\n",
    "        client_secret=config.spotify[\"client_secret\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Quick ping (no user login required)\n",
    "res = sp.search(q=\"test\", limit=1)\n",
    "print(\"Spotify API OK. Sample track:\", res[\"tracks\"][\"items\"][0][\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d8e7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_CACHE_FP = CACHE_DIR / \"audio_features.parquet\"\n",
    "\n",
    "def uri_to_id(uri: str) -> str:\n",
    "    # spotify:track:<id>\n",
    "    return uri.split(\":\")[-1]\n",
    "\n",
    "from spotipy.exceptions import SpotifyException\n",
    "\n",
    "AUDIO_FEATURE_KEYS = [\n",
    "    \"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\n",
    "    \"instrumentalness\",\"liveness\",\"valence\",\"tempo\",\"time_signature\"\n",
    "]\n",
    "\n",
    "def fetch_track_metadata_and_audio_features(track_uris, batch_size: int = 50) -> pd.DataFrame:\n",
    "    track_uris = list(track_uris)\n",
    "    track_ids = [uri_to_id(u) for u in track_uris]\n",
    "\n",
    "    rows = []\n",
    "    audio_features_available = True\n",
    "\n",
    "    for i in tqdm(range(0, len(track_ids), batch_size), desc=\"Spotify tracks()\"):\n",
    "        batch_ids = track_ids[i:i + batch_size]\n",
    "        batch_uris = track_uris[i:i + batch_size]\n",
    "\n",
    "        # Track metadata (works reliably)\n",
    "        tracks_resp = sp.tracks(batch_ids)\n",
    "        tracks = tracks_resp.get(\"tracks\", [])\n",
    "\n",
    "        # Audio features (may be blocked)\n",
    "        feats_by_id = {}\n",
    "        if audio_features_available:\n",
    "            try:\n",
    "                feats = sp.audio_features(batch_ids)\n",
    "                feats_by_id = {f[\"id\"]: f for f in feats if f and f.get(\"id\")}\n",
    "            except SpotifyException as e:\n",
    "                if getattr(e, \"http_status\", None) == 403:\n",
    "                    audio_features_available = False\n",
    "                    print(\n",
    "                        \"\\n⚠️ Spotify /audio-features endpoint blocked (403). \"\n",
    "                        \"Continuing WITHOUT audio features.\\n\"\n",
    "                    )\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        for uri, t in zip(batch_uris, tracks):\n",
    "            if not t:\n",
    "                continue\n",
    "\n",
    "            tid = t.get(\"id\")\n",
    "            album = t.get(\"album\") or {}\n",
    "            artists = t.get(\"artists\") or [{}]\n",
    "\n",
    "            row = {\n",
    "                \"spotify_track_uri\": uri,\n",
    "                \"track_id\": tid,\n",
    "                \"track_popularity\": t.get(\"popularity\"),\n",
    "                \"duration_ms\": t.get(\"duration_ms\"),\n",
    "                \"explicit\": t.get(\"explicit\"),\n",
    "                \"album_release_date\": album.get(\"release_date\"),\n",
    "                \"album_release_date_precision\": album.get(\"release_date_precision\"),\n",
    "                \"artist_id_primary\": artists[0].get(\"id\"),\n",
    "                \"artist_name_primary\": artists[0].get(\"name\"),\n",
    "            }\n",
    "\n",
    "            af = feats_by_id.get(tid)\n",
    "            if af:\n",
    "                for k in AUDIO_FEATURE_KEYS:\n",
    "                    row[k] = af.get(k)\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e291952-4779-4e4a-b9ef-2b66faac0b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio cache found: 25516 cached, 0 missing\n",
      "audio_cache rows: 25516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>album_release_date</th>\n",
       "      <th>album_release_date_precision</th>\n",
       "      <th>artist_id_primary</th>\n",
       "      <th>artist_name_primary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:002AzLaJtX4Tyi7Yv0J49w</td>\n",
       "      <td>002AzLaJtX4Tyi7Yv0J49w</td>\n",
       "      <td>0</td>\n",
       "      <td>210378</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>day</td>\n",
       "      <td>5a8EJtOEbUJDF4RX3mKK02</td>\n",
       "      <td>Woo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:003FTlCpBTM4eSqYSWPv4H</td>\n",
       "      <td>003FTlCpBTM4eSqYSWPv4H</td>\n",
       "      <td>70</td>\n",
       "      <td>233266</td>\n",
       "      <td>False</td>\n",
       "      <td>2002-10-15</td>\n",
       "      <td>day</td>\n",
       "      <td>3vAaWhdBR38Q02ohXqaNHT</td>\n",
       "      <td>The All-American Rejects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:003vvx7Niy0yvhvHt4a68B</td>\n",
       "      <td>003vvx7Niy0yvhvHt4a68B</td>\n",
       "      <td>91</td>\n",
       "      <td>222973</td>\n",
       "      <td>False</td>\n",
       "      <td>2004</td>\n",
       "      <td>year</td>\n",
       "      <td>0C0XlULifJtAgn6ZNCW2eu</td>\n",
       "      <td>The Killers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      spotify_track_uri                track_id  track_popularity  duration_ms  explicit album_release_date album_release_date_precision  \\\n",
       "0  spotify:track:002AzLaJtX4Tyi7Yv0J49w  002AzLaJtX4Tyi7Yv0J49w                 0       210378     False         2020-08-11                          day   \n",
       "1  spotify:track:003FTlCpBTM4eSqYSWPv4H  003FTlCpBTM4eSqYSWPv4H                70       233266     False         2002-10-15                          day   \n",
       "2  spotify:track:003vvx7Niy0yvhvHt4a68B  003vvx7Niy0yvhvHt4a68B                91       222973     False               2004                         year   \n",
       "\n",
       "        artist_id_primary       artist_name_primary  \n",
       "0  5a8EJtOEbUJDF4RX3mKK02                       Woo  \n",
       "1  3vAaWhdBR38Q02ohXqaNHT  The All-American Rejects  \n",
       "2  0C0XlULifJtAgn6ZNCW2eu               The Killers  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build / refresh audio + metadata cache\n",
    "\n",
    "unique_uris = sorted(df[\"spotify_track_uri\"].dropna().unique())\n",
    "\n",
    "if AUDIO_CACHE_FP.exists():\n",
    "    audio_cache = pd.read_parquet(AUDIO_CACHE_FP)\n",
    "    cached_uris = set(audio_cache[\"spotify_track_uri\"].unique())\n",
    "    missing_uris = [u for u in unique_uris if u not in cached_uris]\n",
    "    print(f\"Audio cache found: {len(cached_uris)} cached, {len(missing_uris)} missing\")\n",
    "else:\n",
    "    audio_cache = pd.DataFrame()\n",
    "    missing_uris = unique_uris\n",
    "    print(\"No audio cache found; fetching all tracks...\")\n",
    "\n",
    "if missing_uris:\n",
    "    fetched = fetch_track_metadata_and_audio_features(missing_uris)\n",
    "    print(\"Fetched rows:\", len(fetched))\n",
    "\n",
    "    audio_cache = pd.concat([audio_cache, fetched], ignore_index=True)\n",
    "    audio_cache = audio_cache.drop_duplicates(\n",
    "        subset=[\"spotify_track_uri\"], keep=\"last\"\n",
    "    )\n",
    "    audio_cache.to_parquet(AUDIO_CACHE_FP, index=False)\n",
    "    print(\"Wrote:\", AUDIO_CACHE_FP)\n",
    "\n",
    "print(\"audio_cache rows:\", len(audio_cache))\n",
    "audio_cache.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c138b57-0dfc-4fbc-a54f-8c64298f4560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spotify_track_uri    0.0\n",
       "duration_ms          0.0\n",
       "track_popularity     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_cache[[\"spotify_track_uri\", \"duration_ms\", \"track_popularity\"]].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bfafd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seconds_played  duration_ms  listen_ratio listen_bucket\n",
      "0          21.966       240106      0.091485    skip_early\n",
      "1         454.489       261453      1.500000      complete\n",
      "2          59.112       150693      0.392268       partial\n",
      "3         261.453       261453      1.000000      complete\n",
      "4          22.923       150693      0.152117    skip_early\n",
      "5          35.387       261453      0.135347    skip_early\n",
      "6         160.172       248440      0.644711       partial\n",
      "7         209.413       209413      1.000000      complete\n",
      "8          11.331       256653      0.044149    skip_early\n",
      "9           2.368       203280      0.011649    skip_early\n"
     ]
    }
   ],
   "source": [
    "# Merge enrichment into event-level df\n",
    "\n",
    "df_enriched = df.merge(audio_cache, on='spotify_track_uri', how='left')\n",
    "\n",
    "# Listen ratio (more defensible than a fixed 30-second rule)\n",
    "# Note: duration_ms can be missing for some tracks; handle safely\n",
    "\n",
    "df_enriched['listen_ratio'] = df_enriched['ms_played'] / df_enriched['duration_ms']\n",
    "df_enriched['listen_ratio'] = df_enriched['listen_ratio'].replace([np.inf, -np.inf], np.nan)\n",
    "# Clip extreme ratios (some exports can exceed duration slightly)\n",
    "df_enriched['listen_ratio'] = df_enriched['listen_ratio'].clip(lower=0, upper=1.5)\n",
    "\n",
    "# Buckets for narrative + modeling\n",
    "bins = [-0.01, 0.2, 0.8, 1.5]\n",
    "labels = ['skip_early', 'partial', 'complete']\n",
    "df_enriched['listen_bucket'] = pd.cut(df_enriched['listen_ratio'], bins=bins, labels=labels)\n",
    "\n",
    "print(df_enriched[['seconds_played','duration_ms','listen_ratio','listen_bucket']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cb3c32c-f3e2-475c-8bbe-23cf01e2bb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df rows: 136946\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'duration_ms'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'duration_ms'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration_ms missing rate:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration_ms\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'duration_ms'"
     ]
    }
   ],
   "source": [
    "print(\"df rows:\", len(df))\n",
    "print(\"duration_ms missing rate:\", df[\"duration_ms\"].isna().mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819abae8",
   "metadata": {},
   "source": [
    "## 3) Artist genres (cached)\n",
    "\n",
    "Spotify genres are usually at the **artist** level. We'll:\n",
    "- collect primary artist IDs from track metadata\n",
    "- call `artists()` in batches\n",
    "- cache to `data/cache/artist_genres.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ee0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_CACHE_FP = CACHE_DIR / 'artist_genres.json'\n",
    "\n",
    "def fetch_artist_genres(artist_ids: list[str], batch_size: int = 50) -> dict[str, list[str]]:\n",
    "    out: dict[str, list[str]] = {}\n",
    "    artist_ids = [a for a in artist_ids if isinstance(a, str) and a]\n",
    "\n",
    "    for i in tqdm(range(0, len(artist_ids), batch_size), desc='Spotify artists()'):\n",
    "        batch = artist_ids[i:i+batch_size]\n",
    "        resp = sp.artists(batch)\n",
    "        for a in resp.get('artists', []) or []:\n",
    "            if not a:\n",
    "                continue\n",
    "            out[a.get('id')] = a.get('genres') or []\n",
    "\n",
    "    return out\n",
    "\n",
    "# Load cache if exists\n",
    "if GENRE_CACHE_FP.exists():\n",
    "    artist_genres = json.load(open(GENRE_CACHE_FP, 'r', encoding='utf-8'))\n",
    "else:\n",
    "    artist_genres = {}\n",
    "\n",
    "artist_ids = sorted(set(df_enriched['artist_id_primary'].dropna().astype(str)))\n",
    "missing_ids = [a for a in artist_ids if a not in artist_genres]\n",
    "print('artists total:', len(artist_ids), 'missing:', len(missing_ids))\n",
    "\n",
    "if missing_ids:\n",
    "    new_map = fetch_artist_genres(missing_ids)\n",
    "    artist_genres.update(new_map)\n",
    "    with open(GENRE_CACHE_FP, 'w', encoding='utf-8') as f:\n",
    "        json.dump(artist_genres, f, ensure_ascii=False, indent=2)\n",
    "    print('Wrote:', GENRE_CACHE_FP)\n",
    "\n",
    "# Add genres to enriched df\n",
    "\n",
    "def primary_genre(genres: list[str]) -> str:\n",
    "    if not genres:\n",
    "        return 'unknown'\n",
    "    return genres[0]\n",
    "\n",
    "df_enriched['artist_genres'] = df_enriched['artist_id_primary'].map(artist_genres)\n",
    "df_enriched['artist_genres'] = df_enriched['artist_genres'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df_enriched['primary_genre'] = df_enriched['artist_genres'].apply(primary_genre)\n",
    "\n",
    "df_enriched[['artist_name','artist_name_primary','primary_genre']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895154cc",
   "metadata": {},
   "source": [
    "## 4) Build modeling tables\n",
    "\n",
    "### Event-level table\n",
    "One row per play (keeps context like hour, platform, reason_end).\n",
    "\n",
    "### Track-level table (Day 2 ready)\n",
    "One row per track with aggregated behavior + content features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event-level exports\n",
    "EVENT_FP = PROCESSED_DIR / 'listens_event_level.parquet'\n",
    "\n",
    "# Keep an explicit ordered set of columns\n",
    "event_cols = [\n",
    "    'ts','date','year','month','year_month','dayofweek','hour',\n",
    "    'spotify_track_uri','track_id','track_name','artist_name','artist_id_primary','artist_name_primary','album_name',\n",
    "    'ms_played','seconds_played','duration_ms','listen_ratio','listen_bucket','skipped',\n",
    "    'primary_genre','artist_genres',\n",
    "    'danceability','energy','valence','tempo','acousticness','instrumentalness','liveness','speechiness','loudness','mode','key','time_signature',\n",
    "    'track_popularity','album_release_date',\n",
    "    'reason_start','reason_end','shuffle','platform','conn_country','source_file'\n",
    "]\n",
    "event_cols = [c for c in event_cols if c in df_enriched.columns]\n",
    "\n",
    "listens_event = df_enriched[event_cols].copy()\n",
    "listens_event.to_parquet(EVENT_FP, index=False)\n",
    "print('Wrote:', EVENT_FP)\n",
    "listens_event.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track-level modeling table\n",
    "TRACK_FP = PROCESSED_DIR / 'tracks_modeling_table.parquet'\n",
    "\n",
    "agg = {\n",
    "    'ts': ['min','max'],\n",
    "    'ms_played': ['count','sum','mean'],\n",
    "    'listen_ratio': ['mean','median'],\n",
    "    'skipped': ['mean'],\n",
    "    'seconds_played': ['mean','median'],\n",
    "    'duration_ms': ['first'],\n",
    "}\n",
    "\n",
    "track_df = df_enriched.groupby('spotify_track_uri').agg(agg)\n",
    "track_df.columns = ['_'.join([c for c in col if c]) for col in track_df.columns.values]\n",
    "track_df = track_df.reset_index()\n",
    "\n",
    "# Rename for clarity\n",
    "track_df = track_df.rename(columns={\n",
    "    'ms_played_count': 'play_count',\n",
    "    'ms_played_sum': 'total_ms_played',\n",
    "    'ms_played_mean': 'avg_ms_played',\n",
    "    'skipped_mean': 'skip_rate',\n",
    "    'ts_min': 'first_played_ts',\n",
    "    'ts_max': 'last_played_ts',\n",
    "    'listen_ratio_mean': 'avg_listen_ratio',\n",
    "    'listen_ratio_median': 'median_listen_ratio',\n",
    "    'seconds_played_mean': 'avg_seconds_played',\n",
    "    'seconds_played_median': 'median_seconds_played',\n",
    "    'duration_ms_first': 'duration_ms'\n",
    "})\n",
    "\n",
    "# Join static metadata/audio features (use audio_cache to avoid duplication)\n",
    "meta_cols = [\n",
    "    'spotify_track_uri','track_id','artist_id_primary','artist_name_primary',\n",
    "    'track_popularity','duration_ms','explicit','album_release_date','album_release_date_precision',\n",
    "    'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','time_signature'\n",
    "]\n",
    "meta_cols = [c for c in meta_cols if c in audio_cache.columns]\n",
    "track_meta = audio_cache[meta_cols].drop_duplicates(subset=['spotify_track_uri'])\n",
    "\n",
    "track_df = track_df.merge(track_meta, on='spotify_track_uri', how='left')\n",
    "\n",
    "# Add a representative name/album from event df (most common)\n",
    "name_df = (df_enriched.groupby('spotify_track_uri')\n",
    "           .agg(track_name=('track_name', lambda s: s.mode().iloc[0] if not s.mode().empty else s.iloc[0]),\n",
    "                artist_name=('artist_name', lambda s: s.mode().iloc[0] if not s.mode().empty else s.iloc[0]),\n",
    "                album_name=('album_name', lambda s: s.mode().iloc[0] if not s.mode().empty else s.iloc[0]),\n",
    "                primary_genre=('primary_genre', lambda s: s.mode().iloc[0] if not s.mode().empty else 'unknown'))\n",
    "           .reset_index())\n",
    "\n",
    "track_df = track_df.merge(name_df, on='spotify_track_uri', how='left')\n",
    "\n",
    "# Simple recency (days since last play) for Day 2 ranking\n",
    "now = pd.Timestamp.utcnow()\n",
    "track_df['days_since_last_play'] = (now - pd.to_datetime(track_df['last_played_ts'], utc=True)).dt.total_seconds() / (3600*24)\n",
    "\n",
    "# Save\n",
    "track_df.to_parquet(TRACK_FP, index=False)\n",
    "print('Wrote:', TRACK_FP)\n",
    "track_df.sort_values('play_count', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff236be",
   "metadata": {},
   "source": [
    "## 5) EDA: minimum set of story-ready visuals\n",
    "\n",
    "We will generate four visuals that are strong “blog/dashboard starters”:\n",
    "1. Listening volume over time (monthly)\n",
    "2. Top artists by play count\n",
    "3. Listen ratio distribution\n",
    "4. Genre share over time (top genres)\n",
    "\n",
    "All plots should display CJK titles safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Listening volume over time\n",
    "plt.figure(figsize=(12,4))\n",
    "monthly = listens_event.groupby('year_month').size().sort_index()\n",
    "monthly.plot()\n",
    "plt.title('Listening volume over time (monthly plays)')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Plays')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "fp = FIG_DIR / '01_listening_volume_monthly.png'\n",
    "plt.savefig(fp, dpi=200)\n",
    "print('Saved:', fp)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53eb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Top artists by play count\n",
    "plt.figure(figsize=(10,5))\n",
    "top_artists = listens_event['artist_name'].value_counts().head(15)[::-1]\n",
    "top_artists.plot(kind='barh')\n",
    "plt.title('Top artists by play count')\n",
    "plt.xlabel('Plays')\n",
    "plt.tight_layout()\n",
    "fp = FIG_DIR / '02_top_artists.png'\n",
    "plt.savefig(fp, dpi=200)\n",
    "print('Saved:', fp)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Listen ratio distribution\n",
    "plt.figure(figsize=(10,4))\n",
    "vals = listens_event['listen_ratio'].dropna()\n",
    "plt.hist(vals, bins=50)\n",
    "plt.title('Distribution of listen_ratio (ms_played / duration_ms)')\n",
    "plt.xlabel('listen_ratio')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "fp = FIG_DIR / '03_listen_ratio_distribution.png'\n",
    "plt.savefig(fp, dpi=200)\n",
    "print('Saved:', fp)\n",
    "plt.show()\n",
    "\n",
    "print(listens_event['listen_bucket'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Genre share over time (top 8 genres by volume)\n",
    "\n",
    "# Prepare top genres\n",
    "counts = listens_event['primary_genre'].value_counts()\n",
    "top_genres = counts.head(8).index.tolist()\n",
    "\n",
    "d = listens_event.copy()\n",
    "d['genre_for_plot'] = d['primary_genre'].where(d['primary_genre'].isin(top_genres), other='other')\n",
    "\n",
    "pivot = (d.pivot_table(index='year_month', columns='genre_for_plot', values='spotify_track_uri', aggfunc='count')\n",
    "         .fillna(0)\n",
    "         .sort_index())\n",
    "\n",
    "share = pivot.div(pivot.sum(axis=1), axis=0)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.stackplot(share.index, share.T.values, labels=share.columns)\n",
    "plt.title('Genre share over time (top genres)')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Share of plays')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.02, 1.0))\n",
    "plt.tight_layout()\n",
    "fp = FIG_DIR / '04_genre_share_over_time.png'\n",
    "plt.savefig(fp, dpi=200)\n",
    "print('Saved:', fp)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a597f",
   "metadata": {},
   "source": [
    "## Day 1 ✅ Exit criteria\n",
    "\n",
    "If you got this far, Day 1 is complete:\n",
    "- You have **event-level** and **track-level** modeling tables written to disk\n",
    "- You have **audio features + genres cached**\n",
    "- You generated 4 story-ready visuals\n",
    "\n",
    "Next: Day 2 will build a recommender using the track table (content similarity / TFRS) and evaluate recommendation quality.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
